# ðŸ½ Restaurant Food Sales â€“ End-to-End Data Engineering Pipeline

## 1ï¸âƒ£ Problem Statement

Restaurant Food generates a high volume of daily transactional data across multiple locations.  
The raw Excel files contain inconsistent formats, missing values, and unstructured records, making it difficult to extract reliable insights regarding revenue, orders, promotions, and customer behavior without structured processing.

This project builds a complete **data engineering pipeline** to transform raw sales data into a structured data warehouse and interactive BI dashboards.

## ðŸ“… Data Coverage

**Period:** January 1, 2023 â€“ December 31, 2023  

## ðŸ“‚ Data Source

- Raw data comes from restaurant Excel files ([here](restaurant_sales_2.xlsx)).
- Each file includes order-level transactional details such as:
  - Menu items
  - Quantities
  - Prices and food costs
  - Promotions and discounts
  - Payment methods
  - Restaurant metadata
- Data is processed in Python and loaded into **PostgreSQL (Docker)** for structured storage.


## 2ï¸âƒ£ Business Questions

1. Which menu items generate the highest revenue?  
2. What are the peak hours and days for orders?  
3. How do promotional campaigns influence sales performance?  
4. Which restaurants contribute the most to total revenue?  
5. How do payment methods impact order volume?  
6. How do order size and item category affect profitability?  

## 3ï¸âƒ£ Project Objectives

- Extract raw Excel data into Python.
- Clean, transform, and validate data using ETL processes.
- Design a **star-schema data warehouse** (fact & dimension tables).
- Load structured data into PostgreSQL running in Docker.
- Perform SQL-based analytical queries.
- Build Tableau dashboards to visualize KPIs and performance insights.
- Support operational and strategic decision-making.

## 4ï¸âƒ£ ðŸ›  Technology Stack

1. **Python / Pandas** â€“ ETL, cleaning, transformation, EDA  
2. **Jupyter Notebook** â€“ Interactive data processing  
3. **PostgreSQL (Docker)** â€“ Data warehouse storage  
4. **SQLAlchemy** â€“ Database connection and loading  
5. **Tableau** â€“ Business Intelligence visualization layer  
6. **Docker** â€“ Reproducible database environment  
7. **WSL Ubuntu + VS Code** â€“ Development environment  

## 5ï¸âƒ£ High-Level Architecture

![Data Pipeline Architecture](images/enterprise-ready-architecture-diagram.png)

**Pipeline Flow:**

Excel (Source System)  
â†’ Python ETL (Cleaning & Transformation)  
â†’ PostgreSQL Data Warehouse (Docker)  
â†’ SQL Analysis  
â†’ Tableau Dashboards  

## 6ï¸âƒ£ Project Structure

```
restaurant-sales-data-engineering/
â”œâ”€â”€ ETL Process to Build a Data Pipeline.ipynb
â”œâ”€â”€ Exploratory Data Analysis (EDA).ipynb
â”œâ”€â”€ Restaurant.twb
â”œâ”€â”€ E-R.drawio
â”œâ”€â”€ enterprise-ready-architecture-diagram.drawio
â”œâ”€â”€ images
â”œâ”€â”€ restaurant_sales_2.xlsx
â”œâ”€â”€ SQL_Exercises.md
â”œâ”€â”€ README.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ ingest_data.py
â”œâ”€â”€ SetupProject.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ restaurant_postgres_data/
â””â”€â”€ Restaurant.twb
````


## 7ï¸âƒ£ ðŸ“Š Data Visualizations

The dashboards are organized into **three primary sections**, each designed to answer specific business questions and highlight performance insights.

### 1ï¸âƒ£ Home
Provides a high-level overview of key performance indicators such as total revenue, total orders, and overall sales trends.

![Home Screenshot](images/Home.png)

### 2ï¸âƒ£ Best / Worst
Focuses on performance comparison:
![Best/Worst Screenshot](images/BestWorst.png)

### 3ï¸âƒ£ Detailed Analysis
Offers deeper insights into operational and financial performance:
![Detailed Analysis Screenshot](images/Detailed Analysis.png)

## 8. ðŸ”„ How to Run the Project

To explore and validate this project independently, follow these steps:

1. **Install Dependencies**  
   Ensure Python and the required libraries are installed in your environment.

2. **Execute ETL & EDA Notebooks**  
   Open the Jupyter notebooks and run the ETL process first, followed by the EDA analysis.

3. **Initialize PostgreSQL (Docker)**  
   Launch the PostgreSQL container and load the transformed fact and dimension tables.

4. **Connect Tableau**  
   Connect Tableau to the PostgreSQL database to refresh and interact with the dashboards.

> For a complete setup and execution walkthrough, refer to the `[here](SetupProject.md)` file included in the repository.



